{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "This section is where we prepare for the project, through a variety of initial steps. The steps in this section are as follows:\n",
    "\n",
    "- Importing Packages\n",
    "- Importing Data\n",
    "- Dropping NA Values\n",
    "- Subsetting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from pandas_profiling import ProfileReport\n",
    "\n",
    "#TextBlob Features\n",
    "from textblob import TextBlob\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#SciKit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "#Tensorflow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "path = \"../data/raw/twitter_training.csv\"\n",
    "train_df = pd.read_csv(path, names=[\"Tweet_ID\", \"Entity\", \"Sentiment\", \"Tweet_Content\"])\n",
    "\n",
    "#Test Data (Not to be used until the full model has been trained)\n",
    "test_path = \"../data/raw/twitter_validation.csv\"\n",
    "test_df = pd.read_csv(test_path, names=[\"Tweet_ID\", \"Entity\", \"Sentiment\", \"Tweet_Content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping NA Values\n",
    "\n",
    "Here, we drop any rows with null values, as these miss out on key information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting Data\n",
    "\n",
    "As this dataset is quite large, during the exploration process we begin by subsetting the data during the training process, to speed up any testing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Here, we explore the data, testing if it is balanced, and checking for patterns in missing rows. This can generally be done in an automated fashion with pandas-profiling. The sections under this header include:\n",
    "\n",
    "- Basic visualisation\n",
    "- Automated Data Exploration with pandas-profiling\n",
    "- Checking for balance in output categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Visualisation\n",
    "\n",
    "We can display basic statistics about the data using pandas, and also view a few entries of the dataset, to see example points with which we'll work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 747 entries, 66716 to 23381\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Tweet_ID       747 non-null    int64 \n",
      " 1   Entity         747 non-null    object\n",
      " 2   Sentiment      747 non-null    object\n",
      " 3   Tweet_Content  741 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 29.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#See overall information about the data frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66716</th>\n",
       "      <td>7024</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Johnson &amp; Johnson knowingly sold baby powder c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44820</th>\n",
       "      <td>11697</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Thank you @verizon I was so worried I wouldn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8558</th>\n",
       "      <td>9468</td>\n",
       "      <td>Overwatch</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Umma... Universal chatter is Wildin... \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>1693</td>\n",
       "      <td>CallOfDutyBlackopsColdWar</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>youtube.com/watch?v=Y-yOf8… we life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59800</th>\n",
       "      <td>3449</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>In the Facebook jail for literally fucking not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet_ID                     Entity   Sentiment  \\\n",
       "66716      7024            johnson&johnson    Negative   \n",
       "44820     11697                    Verizon    Positive   \n",
       "8558       9468                  Overwatch  Irrelevant   \n",
       "2838       1693  CallOfDutyBlackopsColdWar  Irrelevant   \n",
       "59800      3449                   Facebook     Neutral   \n",
       "\n",
       "                                           Tweet_Content  \n",
       "66716  Johnson & Johnson knowingly sold baby powder c...  \n",
       "44820  Thank you @verizon I was so worried I wouldn’t...  \n",
       "8558            Umma... Universal chatter is Wildin... \"  \n",
       "2838               youtube.com/watch?v=Y-yOf8… we life    \n",
       "59800  In the Facebook jail for literally fucking not...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display a few entries\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Data Exploration with Pandas-Profiling\n",
    "\n",
    "Pandas-profiling is a library used to automatically explore data. This gives us a good overview of the dataset, which we can use to inform our later work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
    "#profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Balance of the Data in Output Categories\n",
    "\n",
    "We want to check the balance of the output column (Sentiment), such that we don't train a model that always predicts one output. This model might have a high accuracy, but we wouldn't have learned anything about trends in the data, other than the count in the most common sentiment. It might be tempting to think about balancing the test data too, but remember that data in the real world will be unlikely to come nicely balanced, and test data is analagous to real world data\n",
    "\n",
    "\n",
    "The proportion of sentiments ranges from about 0.15 to 0.3, which is generally good balance, such that we are unlikely to see a scenario in which only one class is predicted. We will however be looking out for if our training accuracy forms a plateau at about 0.3, which could be indicative of this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking balance of target classes\n",
    "sentiments = list(df[\"Sentiment\"].unique())\n",
    "\n",
    "sentiment_nums = [len(df[df[\"Sentiment\"] == sentiment]) / len(df) for sentiment in sentiments]\n",
    "\n",
    "plt.bar(sentiments, sentiment_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Enrichment\n",
    "\n",
    "Here, we consider basic features that can enhance the dataset. This will include one-hot encoding of the categorical \"Entity\" variable. We can also use pre-trained NLP systems here to extract features from the text, such as the one from TextBlob, giving us a \"polarity\" and \"subjectivity\" value from any text that we give it. These extra features are added to the dataframe. Sections under this header include:\n",
    "\n",
    "- One-Hot Encoding\n",
    "- Enrichment with Pre-Trained NLP Models (TextBlob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "Here, we create a Boolean column for each possible entity, as there are only 32 of these. 32 columns are added, each signifying if the Tweet was related to the given entity. Each Tweet will only be related to one entity in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['johnson&johnson' 'Verizon' 'Overwatch' 'CallOfDutyBlackopsColdWar'\n",
      " 'Facebook' 'TomClancysRainbowSix' 'HomeDepot' 'FIFA'\n",
      " 'RedDeadRedemption(RDR)' 'Borderlands'\n",
      " 'PlayerUnknownsBattlegrounds(PUBG)' 'Dota2' 'Nvidia' 'Fortnite'\n",
      " 'GrandTheftAuto(GTA)' 'Microsoft' 'Google' 'ApexLegends'\n",
      " 'PlayStation5(PS5)' 'Xbox(Xseries)' 'Hearthstone' 'WorldOfCraft' 'Amazon'\n",
      " 'CallOfDuty' 'Cyberpunk2077' 'Battlefield' 'MaddenNFL' 'LeagueOfLegends'\n",
      " 'CS-GO' 'TomClancysGhostRecon' 'NBA2K' 'AssassinsCreed']\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "#View all possible entities\n",
    "print(df[\"Entity\"].unique())\n",
    "print(len(df[\"Entity\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_Content</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>ApexLegends</th>\n",
       "      <th>AssassinsCreed</th>\n",
       "      <th>Battlefield</th>\n",
       "      <th>Borderlands</th>\n",
       "      <th>CS-GO</th>\n",
       "      <th>...</th>\n",
       "      <th>Overwatch</th>\n",
       "      <th>PlayStation5(PS5)</th>\n",
       "      <th>PlayerUnknownsBattlegrounds(PUBG)</th>\n",
       "      <th>RedDeadRedemption(RDR)</th>\n",
       "      <th>TomClancysGhostRecon</th>\n",
       "      <th>TomClancysRainbowSix</th>\n",
       "      <th>Verizon</th>\n",
       "      <th>WorldOfCraft</th>\n",
       "      <th>Xbox(Xseries)</th>\n",
       "      <th>johnson&amp;johnson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66716</th>\n",
       "      <td>7024</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Johnson &amp; Johnson knowingly sold baby powder c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44820</th>\n",
       "      <td>11697</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Thank you @verizon I was so worried I wouldn’t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8558</th>\n",
       "      <td>9468</td>\n",
       "      <td>Overwatch</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Umma... Universal chatter is Wildin... \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>1693</td>\n",
       "      <td>CallOfDutyBlackopsColdWar</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>youtube.com/watch?v=Y-yOf8… we life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59800</th>\n",
       "      <td>3449</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>In the Facebook jail for literally fucking not...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet_ID                     Entity   Sentiment  \\\n",
       "66716      7024            johnson&johnson    Negative   \n",
       "44820     11697                    Verizon    Positive   \n",
       "8558       9468                  Overwatch  Irrelevant   \n",
       "2838       1693  CallOfDutyBlackopsColdWar  Irrelevant   \n",
       "59800      3449                   Facebook     Neutral   \n",
       "\n",
       "                                           Tweet_Content  Amazon  ApexLegends  \\\n",
       "66716  Johnson & Johnson knowingly sold baby powder c...       0            0   \n",
       "44820  Thank you @verizon I was so worried I wouldn’t...       0            0   \n",
       "8558            Umma... Universal chatter is Wildin... \"       0            0   \n",
       "2838               youtube.com/watch?v=Y-yOf8… we life         0            0   \n",
       "59800  In the Facebook jail for literally fucking not...       0            0   \n",
       "\n",
       "       AssassinsCreed  Battlefield  Borderlands  CS-GO  ...  Overwatch  \\\n",
       "66716               0            0            0      0  ...          0   \n",
       "44820               0            0            0      0  ...          0   \n",
       "8558                0            0            0      0  ...          1   \n",
       "2838                0            0            0      0  ...          0   \n",
       "59800               0            0            0      0  ...          0   \n",
       "\n",
       "       PlayStation5(PS5)  PlayerUnknownsBattlegrounds(PUBG)  \\\n",
       "66716                  0                                  0   \n",
       "44820                  0                                  0   \n",
       "8558                   0                                  0   \n",
       "2838                   0                                  0   \n",
       "59800                  0                                  0   \n",
       "\n",
       "       RedDeadRedemption(RDR)  TomClancysGhostRecon  TomClancysRainbowSix  \\\n",
       "66716                       0                     0                     0   \n",
       "44820                       0                     0                     0   \n",
       "8558                        0                     0                     0   \n",
       "2838                        0                     0                     0   \n",
       "59800                       0                     0                     0   \n",
       "\n",
       "       Verizon  WorldOfCraft  Xbox(Xseries)  johnson&johnson  \n",
       "66716        0             0              0                1  \n",
       "44820        1             0              0                0  \n",
       "8558         0             0              0                0  \n",
       "2838         0             0              0                0  \n",
       "59800        0             0              0                0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot encode using Pandas' get_dummies()\n",
    "onehot = pd.get_dummies(df[\"Entity\"])\n",
    "\n",
    "#Join these new columns back into the DataFrame\n",
    "df = df.join(onehot)\n",
    "\n",
    "#Display a sample of the data with our new columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the Entity column, as we have transformed this data into a more usable format\n",
    "\n",
    "df = df.drop(\"Entity\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrichment with Pre-Trained Models (TextBlob)\n",
    "\n",
    "Here, we use the built-in functionality of TextBlob to add dimensionality to the data, by using it to analyse the text of the \"Tweet_Content\" column, and storing the outputs in a new column.\n",
    "\n",
    "# BEGIN AGAIN FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "AAh\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d1764fe0a03b>\u001b[0m in \u001b[0;36mtb_enrich\u001b[1;34m(ls)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mtb_polarity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mtb_subject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, text, tokenizer, pos_tagger, np_extractor, analyzer, parser, classifier, clean_html)\u001b[0m\n\u001b[0;32m    369\u001b[0m             raise TypeError('The `text` argument passed to `__init__(text)` '\n\u001b[1;32m--> 370\u001b[1;33m                             'must be a string, not {0}'.format(type(text)))\n\u001b[0m\u001b[0;32m    371\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclean_html\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The `text` argument passed to `__init__(text)` must be a string, not <class 'float'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d1764fe0a03b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtb_polarity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_subject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Polarity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Subjectivity\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb_enrich\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Tweet_Content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-d1764fe0a03b>\u001b[0m in \u001b[0;36mtb_enrich\u001b[1;34m(ls)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AAh\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Adding dimensions with textblob\n",
    "def tb_enrich(ls):\n",
    "    #Enriches a column of text with TextBlob Sentiment Analysis outputs\n",
    "    tb_polarity = []\n",
    "    tb_subject = []\n",
    "\n",
    "    for tweet in ls:\n",
    "        try:\n",
    "            tb_polarity.append(TextBlob(tweet).sentiment[0])\n",
    "            tb_subject.append(TextBlob(tweet).sentiment[1])\n",
    "        except:\n",
    "            print(tweet)\n",
    "            if np.isnan(tweet):\n",
    "                print(\"AAh\")\n",
    "            raise NotImplementedError\n",
    "    \n",
    "\n",
    "    return tb_polarity, tb_subject\n",
    "    \n",
    "df[\"Polarity\"], df[\"Subjectivity\"] = tb_enrich(list(df[\"Tweet_Content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will likely go under a header like \"data enrichment and editing\"\n",
    "- Creating Indexers for the Output Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-1455e24a5c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcount_na\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Tweet_Content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcount_na\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-1455e24a5c5d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcount_na\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Tweet_Content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcount_na\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "count_na = len([np.isnan(tweet) for tweet in list(df[\"Tweet_Content\"])])\n",
    "count_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
